{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recetas de cocina para limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath = \"C:/Users/gerar/OneDrive/Documentos/\"\n",
    "carpet = \"Curso Machine Learning Data Science/python-ml-course-master/datasets\"\n",
    "path = mainpath + carpet\n",
    "filename = \"titanic/titanic3.csv\"\n",
    "fullpath = os.path.join(path, filename)\n",
    "\n",
    "url_dataset = \"insertar url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set\n",
    "data = pd.read_csv(fullpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------- Función para limpiar, ordenar y guardar dataset previamente cargado y leído ----------\n",
    "\n",
    "*Revisar nombre, dirección y formato a guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDataset(dataset, delim = \"\\n\", sep = \",\"):\n",
    "    # Se divide el string en un array de filas separandolos por intros\n",
    "    lines = dataset.split(delim)\n",
    "\n",
    "    # Se extrae la primera línea (cabecera)\n",
    "    head_line = lines[0].split(sep)\n",
    "    n_cols = len(head_line)\n",
    "\n",
    "    # Se genera un diccionario vacío para la info procesada de la URL externa\n",
    "    empty_dict = {}\n",
    "    contador = 0\n",
    "    for col in head_line:\n",
    "        empty_dict[col] = []\n",
    "\n",
    "    # Procesamos fila por fila la info para rellenar el diccionario con los datos\n",
    "    for line in lines:\n",
    "\n",
    "        # Nos saltamos la cabecera que ya se tiene procesada\n",
    "        if (contador > 0):\n",
    "\n",
    "            # Se divide cada string por comas como elemento separador\n",
    "            values = line.strip().split(',')\n",
    "\n",
    "            # Añadimos cada valor a su respectiva columna del diccionario\n",
    "            for i in range(n_cols):\n",
    "                empty_dict[head_line[i]].append(values[i])\n",
    "        contador+=1\n",
    "\n",
    "    new_DataFrame = pd.DataFrame(empty_dict)\n",
    "    print(new_DataFrame)\n",
    "\n",
    "    # Se elige donde se guardará\n",
    "    mainpath = \"C:/Users/gerar/OneDrive/Documentos/Curso Machine Learning Data Science/python-ml-course-master/datasets\"\n",
    "    filepath = \"athletes/medals\"\n",
    "    fullpath = os.path.join(mainpath, filepath)\n",
    "\n",
    "    # Se guarda en el archivo deseado\n",
    "    new_DataFrame.to_csv(fullpath + \".csv\")\n",
    "    new_DataFrame.to_json(fullpath + \".json\")\n",
    "    new_DataFrame.to_excel(fullpath + \".xls\")\n",
    "    \n",
    "    print('\\nLos ficheros se han guardado correctamente en: ' + fullpath)\n",
    "    \n",
    "    return new_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanDataset(dataset = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------- Función para obtener dataset desde URL, decodificarlo, limpiarlo, ordenarlo y guardarlo ----------\n",
    "\n",
    "*Revisar dirección URL, nombre, dirección y formato a guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFromURL(URL, filepath, sep = ',', delim = '\\n', encoding = 'utf-8'):\n",
    "\n",
    "    import urllib3\n",
    "    http = urllib3.PoolManager()\n",
    "    r = http.request('GET', url_dataset)\n",
    "    print('\\n El estado de la respuesta es %d \\n' %r.status)\n",
    "    response = r.data\n",
    "\n",
    "    # El objeto response contiene un string binario y se decodifica en UTF-8 para convertir a string\n",
    "    str_data = response.decode(encoding)\n",
    "\n",
    "    # Se divide el string en un array de filas separandolos por intros\n",
    "    lines = str_data.split(delim)\n",
    "\n",
    "    # Se extrae la primera línea (cabecera)\n",
    "    head_line = lines[0].split(sep)\n",
    "    n_cols = len(head_line)\n",
    "\n",
    "    # Se genera un diccionario vacío para la info procesada de la URL externa\n",
    "    empty_dict = {}\n",
    "    contador = 0\n",
    "    for col in head_line:\n",
    "        empty_dict[col] = []\n",
    "\n",
    "    # Procesamos fila por fila la info para rellenar el diccionario con los datos\n",
    "    for line in lines:\n",
    "\n",
    "        # Nos saltamos la cabecera que ya se tiene procesada\n",
    "        if (contador > 0):\n",
    "\n",
    "            # Se divide cada string por comas como elemento separador\n",
    "            values = line.strip().split(',')\n",
    "\n",
    "            # Añadimos cada valor a su respectiva columna del diccionario\n",
    "            for i in range(n_cols):\n",
    "                empty_dict[head_line[i]].append(values[i])\n",
    "        contador+=1\n",
    "\n",
    "    url_dataframe = pd.DataFrame(empty_dict)\n",
    "    print(url_dataframe)\n",
    "\n",
    "    # Se elige donde se guardará\n",
    "    mainpath = \"C:/Users/gerar/OneDrive/Documentos/Curso Machine Learning Data Science/python-ml-course-master/datasets\"\n",
    "    filepath = \"athletes/medals\"\n",
    "    fullpath = os.path.join(mainpath, filepath)\n",
    "\n",
    "    # Se guarda en el archivo deseado\n",
    "    #url_dataframe.to_csv(fullpath + \".csv\")\n",
    "    #url_dataframe.to_json(fullpath + \".json\")\n",
    "    #url_dataframe.to_excel(fullpath + \".xls\")\n",
    "    \n",
    "    print('\\nLos ficheros se han guardado correctamente en: ' + fullpath)\n",
    "    \n",
    "    return url_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloadFromURL(url_dataset = \"\", filepath = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------- Función para crear variables dummy según la variable dada como parámetro para X dataset ----------\n",
    "\n",
    "*Revisar si la variable aplica para separarse en dummy y si es renglón/columna (axis = ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso automático\n",
    "\n",
    "def createDummies(data_frame, var_name):\n",
    "    dummy = pd.get_dummies(data_frame[var_name], prefix = var_name)\n",
    "    data_frame = data_frame.drop(var_name, axis = 1)\n",
    "    data_frame = pd.concat([data_frame, dummy], axis = 1)\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createDummies(data, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
